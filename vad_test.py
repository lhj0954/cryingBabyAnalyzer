import torch
import torchaudio
import wave
import struct
import math
import os

# ì½˜ì†” ì¶œë ¥ êµ¬ë¶„ì„ 
DIVIDER = "-" * 50

print("\n" + DIVIDER)
print("ğŸ› ï¸  Silero VAD ëª¨ë¸ êµ¬ë™ í…ŒìŠ¤íŠ¸ (ìŒì„± ê°ì§€ ì‹œì—°ìš©)")
print(DIVIDER)

# 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
print("[Step 1] ëª¨ë¸ ë¡œë”© ì¤‘...")
try:
    model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                                  model='silero_vad',
                                  trust_repo=True)
    (get_speech_timestamps, _, _, _, _) = utils
    print("   âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"   âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit()

# 2. 'ê°€ì§œ ì‚¬ëŒ ëª©ì†Œë¦¬' íŒŒì¼ ìƒì„±
# ë‹¨ìˆœ ì‚~ ì†Œë¦¬ ëŒ€ì‹ , ì‚¬ëŒ ëª©ì†Œë¦¬ í†¤(ê¸°ë³¸ìŒ+ë°°ìŒ)ì„ í‰ë‚´ ë‚¸ ì†Œë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.
filename = "my_test_audio.wav"
print(f"\n[Step 2] í…ŒìŠ¤íŠ¸ìš© ì˜¤ë””ì˜¤ ìƒì„± (ì‚¬ëŒ ëª©ì†Œë¦¬ í‰ë‚´)")
try:
    with wave.open(filename, "w") as f:
        f.setnchannels(1)      
        f.setsampwidth(2)      
        f.setframerate(16000)  
        
        audio_data = b''
        # 3ì´ˆ ê¸¸ì´ ìƒì„±
        for i in range(16000 * 3):
            t = i / 16000
            # 1ì´ˆ ~ 2.5ì´ˆ ì‚¬ì´ì— ì†Œë¦¬ ë„£ê¸°
            if 1.0 <= t <= 2.5:
                # 150Hz(ë‚¨ì ì €ìŒ) + ë°°ìŒë“¤ì„ ì„ì–´ì„œ ëª©ì†Œë¦¬ì²˜ëŸ¼ ë“¤ë¦¬ê²Œ í•¨
                val = math.sin(2 * math.pi * 150 * t)       # ê¸°ë³¸ìŒ
                val += 0.5 * math.sin(2 * math.pi * 300 * t) # ë°°ìŒ 1
                val += 0.25 * math.sin(2 * math.pi * 450 * t) # ë°°ìŒ 2
                sample = int(10000 * val)
            else:
                sample = 0
            # ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šê²Œ í´ë¦¬í•‘
            sample = max(-32767, min(32767, sample))
            audio_data += struct.pack('<h', sample)
            
        f.writeframes(audio_data)
    print("   âœ… ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì™„ë£Œ")
except Exception as e:
    print(f"   âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
    exit()

# 3. íŒŒì¼ ì½ê¸°
print(f"\n[Step 3] ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ")
wav, sr = torchaudio.load(filename)

# 4. ëª¨ë¸ ì‹¤í–‰ (ê°•ì œ ê°ì§€ ëª¨ë“œ)
print(f"\n[Step 4] VAD ì¶”ë¡  ì‹¤í–‰ ì¤‘...")
# threshold=0.3 : ê°ì§€ ê¸°ì¤€ì„ ì•½ê°„ ë‚®ì¶°ì„œ ê¸°ê³„ìŒë„ ì˜ ì¡ê²Œ ì„¤ì •
speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sr, threshold=0.3)

# 5. ê²°ê³¼ ë¦¬í¬íŠ¸
print("\n" + DIVIDER)
print("ğŸ“Š  [ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸]")

if len(speech_timestamps) > 0:
    print(f"   ğŸ‰ ê°ì§€ ì„±ê³µ! ì´ {len(speech_timestamps)}ê°œì˜ êµ¬ê°„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    for i, ts in enumerate(speech_timestamps):
        start_sec = ts['start'] / sr
        end_sec = ts['end'] / sr
        print(f"      ğŸ‘‰ êµ¬ê°„ {i+1}: {start_sec:.3f}ì´ˆ ~ {end_sec:.3f}ì´ˆ (ìŒì„± ì¸ì‹ë¨)")
else:
    print("   âš ï¸ ì—¬ì „íˆ ê°ì§€ë˜ì§€ ì•ŠìŒ (ë³¼ë¥¨ì´ë‚˜ ì£¼íŒŒìˆ˜ ì¡°ì • í•„ìš”)")

print(DIVIDER + "\n")
